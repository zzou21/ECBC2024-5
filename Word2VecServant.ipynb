{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd08f098",
   "metadata": {},
   "source": [
    "This Jupyter notebook tests the performance of word2vec on identifying words similar in usage to \"servant\" from EEBO texts. Spring 2025.\n",
    "\n",
    "By Kirin Mohile and Jerry Zou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49eb5bae-e9e8-4143-b2c0-ce2fe789c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords \n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# Get the set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove punctuation, numbers, and stop words using regex\n",
    "    # \\b[a-zA-Z]+\\b matches only alphabetic words (removes punctuation and numbers)\n",
    "    words = [word.lower() for word in re.findall(r'\\b[a-zA-Z]+\\b', text)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3e968fe8-a3a7-4e89-ab75-8108466f76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\kmm212\\Documents\\EEBOdataALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7fc5bbfc-0ca5-4b4d-bed1-c3c55381ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labelled Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“His father also was very wealthy, hauing many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“From which imputation the Lord would free his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“​​The Lord then doth promise to make all his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Hee that raised vp those godly men friends ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And thus the Prophet Zacharie bringing foorth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“So much the more ignorant we are of knowing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Many worthy sonnes and seruants of God, aswell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“let them taste of thy fauours and loue contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AS there is areciprocal dutie between the husb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Make the case of your corporall seruants disob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Labelled Sentences\n",
       "0  “His father also was very wealthy, hauing many...\n",
       "1  “From which imputation the Lord would free his...\n",
       "2  “​​The Lord then doth promise to make all his ...\n",
       "3  “Hee that raised vp those godly men friends ab...\n",
       "4  And thus the Prophet Zacharie bringing foorth ...\n",
       "5  “So much the more ignorant we are of knowing w...\n",
       "6  Many worthy sonnes and seruants of God, aswell...\n",
       "7  “let them taste of thy fauours and loue contin...\n",
       "8  AS there is areciprocal dutie between the husb...\n",
       "9  Make the case of your corporall seruants disob..."
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8300c68c-8ae2-4c4e-8fb2-e0dae5abe25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"Labelled Sentences\"].values\n",
    "sentenceVec = [clean_text(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6adfc78e-80da-456f-8bc9-45809e738fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentenceVec,min_count=1,vector_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2bb351ad-1bee-403a-8b22-4076850b332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('but', 0.599021315574646),\n",
       " ('goe', 0.547112762928009),\n",
       " ('imply', 0.5244221091270447),\n",
       " ('what', 0.5040825009346008),\n",
       " ('implied', 0.49454736709594727),\n",
       " ('longer', 0.4848790466785431),\n",
       " ('held', 0.46419757604599),\n",
       " ('willingly', 0.4548797309398651),\n",
       " ('a', 0.45085760951042175),\n",
       " ('way', 0.44341328740119934)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('seruant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6201597f-3767-47b3-9d6e-52056e481f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('goe', 0.547112762928009), ('imply', 0.5244221091270447), ('implied', 0.49454736709594727), ('longer', 0.4848790466785431), ('held', 0.46419757604599), ('willingly', 0.4548797309398651), ('way', 0.44341328740119934), ('liue', 0.43995875120162964), ('meerely', 0.4342024624347687), ('mistresses', 0.41352418065071106), ('doth', 0.40915006399154663), ('sciences', 0.40911513566970825), ('great', 0.3868977129459381), ('example', 0.38597995042800903)]\n"
     ]
    }
   ],
   "source": [
    "def get_most_similar_excluding_stopwords(model, word, topn=10):\n",
    "    if word not in model.wv.key_to_index:\n",
    "        return f\"Word '{word}' not in vocabulary.\"\n",
    "    \n",
    "    similar_words = model.wv.most_similar(word, topn=topn)\n",
    "    # Filter out stopwords from the most similar words\n",
    "    filtered_similar_words = [(w, sim) for w, sim in similar_words if w not in stop_words]\n",
    "    \n",
    "    return filtered_similar_words\n",
    "\n",
    "# Query the most similar words to 'servant', excluding stop words, and get top 20 similar words\n",
    "similar_words = get_most_similar_excluding_stopwords(model, 'seruant', topn=20)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fc2b8285-4b1f-4f40-a988-9766629ab3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00960584,  0.00890332,  0.02065947, -0.01186525,  0.00826552,\n",
       "       -0.03135111,  0.03304799,  0.03098423, -0.01740754,  0.00103027,\n",
       "        0.00607685,  0.01041439, -0.02622513, -0.00124748,  0.0228003 ,\n",
       "        0.00550258,  0.00252749, -0.02692831,  0.02543562, -0.00816675,\n",
       "       -0.0001763 ,  0.0222545 ,  0.01088543,  0.0032712 ,  0.00706901,\n",
       "       -0.02254255, -0.03993632,  0.03189945,  0.0200764 , -0.02774495,\n",
       "        0.00968992,  0.0035363 ], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['seruant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a9ee31fb-92d0-42e0-bc67-82880941f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061343446\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('seruant', 'god')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2ed27",
   "metadata": {},
   "source": [
    "Analyzing sentences with different word2vec vector lengths and window sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c568dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "allSentencesDF = pd.read_csv(\"/Users/Jerry/Desktop/BassConnections2024-5/ECBC2024-5/EEBOdataALL.csv\")\n",
    "allSentences = allSentencesDF[\"Labelled Sentences\"].tolist()\n",
    "print(type(allSentences))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e3bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())  # Remove punctuation and lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return tokens\n",
    "\n",
    "tokenizedSentences = [preprocess(sentence) for sentence in allSentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f26656d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedWithStopwords = Word2Vec(sentences=tokenizedSentences, vector_size=300, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Words most similar to 'seruant': [('shew', 0.17914585769176483), ('length', 0.16879016160964966), ('filld', 0.16274015605449677), ('church', 0.1569209098815918), ('schoole', 0.15550550818443298), ('looke', 0.15275436639785767), ('thou', 0.14728382229804993), ('salary', 0.1465924084186554), ('corrupting', 0.14316125214099884), ('commanded', 0.14269207417964935)]\n"
     ]
    }
   ],
   "source": [
    "similarWords = embedWithStopwords.wv.most_similar(\"seruant\", topn=10)\n",
    "print(type(similarWords))\n",
    "print(\"Words most similar to 'seruant':\", similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d9d41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two sets of models. One has 4 versions with different vector lengths. The other has the same vector length (300 dimensions) but with different window sizes.\n",
    "modelsDifferentVectorSize = {}\n",
    "for vectorLength in [100, 200, 300, 400]:\n",
    "    modelsDifferentVectorSize[f'vector_{vectorLength}'] = Word2Vec(\n",
    "        sentences=tokenizedSentences,\n",
    "        vector_size=vectorLength,\n",
    "        window=5,\n",
    "        min_count=1,\n",
    "        workers=4\n",
    "    )\n",
    "\n",
    "\n",
    "modelsDifferentWindowSize = {}\n",
    "for windowSize in [4, 6, 8, 10]:\n",
    "    modelsDifferentWindowSize[f'window_{windowSize}'] = Word2Vec(\n",
    "        sentences=tokenizedSentences,\n",
    "        vector_size=300,\n",
    "        window=windowSize,\n",
    "        min_count=1,\n",
    "        workers=4\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be3196b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words similar to 'seruant' with vector length=vector_100:\n",
      "('iudicially', 0.3639525771141052)\n",
      "('stipend', 0.22085310518741608)\n",
      "('sister', 0.21995605528354645)\n",
      "('presumption', 0.2175326943397522)\n",
      "('exceedingly', 0.21661525964736938)\n",
      "('censure', 0.21420413255691528)\n",
      "('doctor', 0.21195511519908905)\n",
      "('mispend', 0.2071177065372467)\n",
      "('secrets', 0.20537249743938446)\n",
      "('sit', 0.2009040117263794)\n",
      "Top words similar to 'seruant' with vector length=vector_200:\n",
      "('liberall', 0.20895951986312866)\n",
      "('messengers', 0.18673625588417053)\n",
      "('lot', 0.1794871836900711)\n",
      "('115', 0.17131057381629944)\n",
      "('till', 0.16365258395671844)\n",
      "('haue', 0.16234120726585388)\n",
      "('respect', 0.15825983881950378)\n",
      "('grapes', 0.15748943388462067)\n",
      "('raised', 0.15035907924175262)\n",
      "('deuout', 0.14684529602527618)\n",
      "Top words similar to 'seruant' with vector length=vector_300:\n",
      "('shew', 0.17914585769176483)\n",
      "('length', 0.16879016160964966)\n",
      "('filld', 0.16274015605449677)\n",
      "('church', 0.1569209098815918)\n",
      "('schoole', 0.15550550818443298)\n",
      "('looke', 0.15275436639785767)\n",
      "('thou', 0.14728382229804993)\n",
      "('salary', 0.1465924084186554)\n",
      "('corrupting', 0.14316125214099884)\n",
      "('commanded', 0.14269207417964935)\n",
      "Top words similar to 'seruant' with vector length=vector_400:\n",
      "('serud', 0.16297821700572968)\n",
      "('bad', 0.15863777697086334)\n",
      "('lord', 0.14748403429985046)\n",
      "('needing', 0.1473008543252945)\n",
      "('nature', 0.14398056268692017)\n",
      "('houshold', 0.12409217655658722)\n",
      "('king', 0.121951624751091)\n",
      "('parents', 0.11791936308145523)\n",
      "('put', 0.1149880513548851)\n",
      "('taming', 0.11488725244998932)\n",
      "vector_100\n",
      "['iudicially', 'stipend', 'sister', 'presumption', 'exceedingly', 'censure', 'doctor', 'mispend', 'secrets', 'sit']\n",
      "vector_200\n",
      "['liberall', 'messengers', 'lot', '115', 'till', 'haue', 'respect', 'grapes', 'raised', 'deuout']\n",
      "vector_300\n",
      "['shew', 'length', 'filld', 'church', 'schoole', 'looke', 'thou', 'salary', 'corrupting', 'commanded']\n",
      "vector_400\n",
      "['serud', 'bad', 'lord', 'needing', 'nature', 'houshold', 'king', 'parents', 'put', 'taming']\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "target_word = \"seruant\"\n",
    "simialrWordsStorage = {}\n",
    "counter = set()\n",
    "for vectorLength, model in modelsDifferentVectorSize.items():\n",
    "    print(f\"Top words similar to '{target_word}' with vector length={vectorLength}:\")\n",
    "    simialrWordsStorage[vectorLength] = []\n",
    "    try:\n",
    "        resultsList = model.wv.most_similar(target_word, topn=10)\n",
    "        for wordResult in resultsList:\n",
    "            print(wordResult)\n",
    "            counter.add(wordResult[0])\n",
    "            simialrWordsStorage[vectorLength].append(wordResult[0])\n",
    "    except KeyError:\n",
    "        print(f\"'{target_word}' not found in the vocabulary for vector length={vectorLength}.\")\n",
    "\n",
    "for vectorVersion, wordList in simialrWordsStorage.items():\n",
    "    print(vectorVersion)\n",
    "    print(wordList)\n",
    "\n",
    "print(len(counter))\n",
    "# target_word = \"seruant\"\n",
    "# for windowSize, model in modelsDifferentWindowSize.items():\n",
    "#     print(f\"Top words similar to '{target_word}' with window size={windowSize}:\")\n",
    "#     try:\n",
    "#         resultsList = model.wv.most_similar(target_word, topn=10)\n",
    "#         for wordResult in resultsList:\n",
    "#             print(wordResult)\n",
    "#     except KeyError:\n",
    "#         print(f\"'{target_word}' not found in the vocabulary for window size={windowSize}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
