{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "49eb5bae-e9e8-4143-b2c0-ce2fe789c6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kmm212\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords \n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Get the set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove punctuation, numbers, and stop words using regex\n",
    "    # \\b[a-zA-Z]+\\b matches only alphabetic words (removes punctuation and numbers)\n",
    "    words = [word.lower() for word in re.findall(r'\\b[a-zA-Z]+\\b', text)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3e968fe8-a3a7-4e89-ab75-8108466f76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\kmm212\\Documents\\EEBOdataALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7fc5bbfc-0ca5-4b4d-bed1-c3c55381ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labelled Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“His father also was very wealthy, hauing many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“From which imputation the Lord would free his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“​​The Lord then doth promise to make all his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Hee that raised vp those godly men friends ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And thus the Prophet Zacharie bringing foorth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“So much the more ignorant we are of knowing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Many worthy sonnes and seruants of God, aswell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“let them taste of thy fauours and loue contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AS there is areciprocal dutie between the husb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Make the case of your corporall seruants disob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Labelled Sentences\n",
       "0  “His father also was very wealthy, hauing many...\n",
       "1  “From which imputation the Lord would free his...\n",
       "2  “​​The Lord then doth promise to make all his ...\n",
       "3  “Hee that raised vp those godly men friends ab...\n",
       "4  And thus the Prophet Zacharie bringing foorth ...\n",
       "5  “So much the more ignorant we are of knowing w...\n",
       "6  Many worthy sonnes and seruants of God, aswell...\n",
       "7  “let them taste of thy fauours and loue contin...\n",
       "8  AS there is areciprocal dutie between the husb...\n",
       "9  Make the case of your corporall seruants disob..."
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8300c68c-8ae2-4c4e-8fb2-e0dae5abe25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"Labelled Sentences\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c796c8-d0f2-49b4-9271-fca64b92cde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7a8f3257-493f-4a14-970b-03390bda2e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kmm212\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kmm212\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b98fc24f-ec4c-4820-8a0c-a50b75e34cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceVec = [clean_text(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6adfc78e-80da-456f-8bc9-45809e738fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentenceVec,min_count=1,vector_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2bb351ad-1bee-403a-8b22-4076850b332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('but', 0.599021315574646),\n",
       " ('goe', 0.547112762928009),\n",
       " ('imply', 0.5244221091270447),\n",
       " ('what', 0.5040825009346008),\n",
       " ('implied', 0.49454736709594727),\n",
       " ('longer', 0.4848790466785431),\n",
       " ('held', 0.46419757604599),\n",
       " ('willingly', 0.4548797309398651),\n",
       " ('a', 0.45085760951042175),\n",
       " ('way', 0.44341328740119934)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('seruant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6201597f-3767-47b3-9d6e-52056e481f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('goe', 0.547112762928009), ('imply', 0.5244221091270447), ('implied', 0.49454736709594727), ('longer', 0.4848790466785431), ('held', 0.46419757604599), ('willingly', 0.4548797309398651), ('way', 0.44341328740119934), ('liue', 0.43995875120162964), ('meerely', 0.4342024624347687), ('mistresses', 0.41352418065071106), ('doth', 0.40915006399154663), ('sciences', 0.40911513566970825), ('great', 0.3868977129459381), ('example', 0.38597995042800903)]\n"
     ]
    }
   ],
   "source": [
    "def get_most_similar_excluding_stopwords(model, word, topn=10):\n",
    "    if word not in model.wv.key_to_index:\n",
    "        return f\"Word '{word}' not in vocabulary.\"\n",
    "    \n",
    "    similar_words = model.wv.most_similar(word, topn=topn)\n",
    "    # Filter out stopwords from the most similar words\n",
    "    filtered_similar_words = [(w, sim) for w, sim in similar_words if w not in stop_words]\n",
    "    \n",
    "    return filtered_similar_words\n",
    "\n",
    "# Query the most similar words to 'servant', excluding stop words, and get top 20 similar words\n",
    "similar_words = get_most_similar_excluding_stopwords(model, 'seruant', topn=20)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fc2b8285-4b1f-4f40-a988-9766629ab3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00960584,  0.00890332,  0.02065947, -0.01186525,  0.00826552,\n",
       "       -0.03135111,  0.03304799,  0.03098423, -0.01740754,  0.00103027,\n",
       "        0.00607685,  0.01041439, -0.02622513, -0.00124748,  0.0228003 ,\n",
       "        0.00550258,  0.00252749, -0.02692831,  0.02543562, -0.00816675,\n",
       "       -0.0001763 ,  0.0222545 ,  0.01088543,  0.0032712 ,  0.00706901,\n",
       "       -0.02254255, -0.03993632,  0.03189945,  0.0200764 , -0.02774495,\n",
       "        0.00968992,  0.0035363 ], dtype=float32)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['seruant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a9ee31fb-92d0-42e0-bc67-82880941f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061343446\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('seruant', 'god')\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
